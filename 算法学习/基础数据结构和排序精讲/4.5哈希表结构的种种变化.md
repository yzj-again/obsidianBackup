---
tags:
  - 算法
  - 哈希表
date: 2025-01-04
---
## 用链表加强哈希表

前文[[4.1哈希表核心原理]]从原理上分析了，不能依赖哈希表遍历 `key` 的顺序，即哈希表中的 `key` 是无序的。

但结合实际的编程经验，你可能会有些疑问。

比如熟悉 Python 的读者可能知道，Python 3.7 开始，标准库提供的哈希表 `dict` 就明确告诉你了，**`dict` 的键的遍历顺序就是键的插入顺序**。比如下面这段简单的代码：

```python
d = dict()

d['a'] = 1
d['b'] = 2
d['c'] = 3
print(list(d.keys()))  # ['a', 'b', 'c']

d['y'] = 4
print(list(d.keys()))  # ['a', 'b', 'c', 'y']

d['d'] = 5
print(list(d.keys()))  # ['a', 'b', 'c', 'y', 'd']
```

无论你插入多少键，`keys` 方法返回的所有键都是按照插入顺序排列，感觉就好像在向数组尾部追加元素一样。这怎么可能呢？

如果你熟悉 Golang，你会发现一个更神奇的现象。比如下面这段测试代码：

```go
package main

import (
	"fmt"
)

func main() {
	// 初始化 map
	myMap := map[string]int{
		"1": 1,
		"2": 2,
		"3": 3,
		"4": 4,
		"5": 5,
	}

	// 定义遍历 map 的函数
	printMapKeys := func(m map[string]int) {
		for key := range m {
			fmt.Print(key, " ")
		}
		fmt.Println()
	}

	// 多次遍历 map，观察键的顺序
	printMapKeys(myMap)
	printMapKeys(myMap)
	printMapKeys(myMap)
	printMapKeys(myMap)
}

// 我运行的结果如下：
// 1 2 3 4 5
// 5 1 2 3 4
// 2 3 4 5 1
// 1 2 3 4 5
```

也就是说，它每次遍历的顺序都是随机。但是按照前文 [[4.1哈希表核心原理]] 所说，虽然哈希表的键是无序的，但是没有对哈希表做任何操作，遍历得到的结果应该不会变才对，Golang 的 map 每次遍历的顺序咋都不一样？这也太离谱了吧？

你可以先自己思考下原因，下面我给出答案。

> **先说 Golang 吧，每次遍历都乱序的原因就是，它故意的**。
> 
> 这个原因属实是让人有些哭笑不得，Golang 为了防止开发者依赖哈希表的遍历顺序，所以每次遍历都故意返回不同的顺序，可谓用心良苦。也可以从侧面看出，确实不少开发者没了解过哈希表的基本原理。
> 
> 我们不妨进一步想想，它是怎么打乱顺序的呢？真是随机打乱吗？
> 
> 其实不是，你仔细看看，它这个乱序是有规律的。有没有想起前面讲过的环形数组？
> ```plain
> | 1 2 3 4 5
> 5 | 1 2 3 4
> 2 3 4 5 | 1
> | 1 2 3 4 5
> ```
> 
> 看出来没有？如果不触发扩缩容的话，实际上它的遍历顺序应该也是固定的，只不过它不是每次都从底层 `table` 数组的头部开始，而是从一个随机的位置开始，然后利用环形数组技巧遍历整个 `table` 数组，这样就能保证多次遍历的顺序具有随机性。
> 
> 再说 Python，**它能让所有键按照插入顺序排列，是因为它把标准的哈希表和链表结合起来，组成了一种新的数据结构：哈希链表**。
> 
> 其他编程语言也有类似的实现，比如 Java 的 `LinkedHashMap`。这种数据结构兼具了哈希表 O(1)O(1) 的增删查改效率，同时又可以像数组链表一样保持键的插入顺序。

### 哈希链表（LinkedHashMap）实现思路

我们先明确一下问题。

标准哈希表的键是无序存储在底层的 table 数组中的：

![image.png](https://typora-yzj.oss-cn-hangzhou.aliyuncs.com/img/20250104232206.png)

你光看这个图，看不出来这些键是按什么顺序插入的，且一旦触发扩缩容，这键的位置又会改变。

我们现在希望在==不改变哈希表增删查改复杂度==的前提下，能够==按照插入顺序来访问所有键==，且不受扩缩容影响。

那么一个最直接的思路就是，我想办法把这些键值对都用类似链表节点的结构串联起来，持有一个头尾结点 `head, taile` 的引用，每次把新的键插入 table 数组时，同时把这个键插入链表的尾部。

这样一来，只要我从头结点 `head` 开始遍历链表，就能按照插入顺序访问所有键了：

![image.png](https://typora-yzj.oss-cn-hangzhou.aliyuncs.com/img/20250105011356.png)

我们可以清楚地看出，键的插入顺序是 `k2, k4, k5, k3, k1`。

> 抽象来看，哈希表本质上就是一个键值映射，链表本质上就是一个顺序存储元素的容器。现在我就是想让这个键值映射中的键按照插入顺序排列，怎么把哈希表和链表结合起来？
> 
> 答案是这样：
> 
> ![image.png](https://typora-yzj.oss-cn-hangzhou.aliyuncs.com/img/20250105011508.png)

假设键和值都是字符串类型，标准的哈希表是这样：

```java
HashMap<String, String> map = new HashMap<>();
```

而我们现在给哈希表的值类型套了一层双链表结构：

```java
// 双链表节点
class Node {
    String key;
    String value;
    Node prev;
    Node next;

    Node(String key, String value) {
        this.key = key;
        this.value = value;
    }
}

HashMap<String, Node> map = new HashMap<>();
```

这样一来，就实现了哈希链表结构：

- 我们还是可以在 $O(1)$ 的时间复杂度内通过键查找到对应的双链表节点，进而找到键对应的值。
- 我们可以在 $O(1)$ 的时间复杂度内插入新的键值对。因为哈希表本身的插入操作时间复杂度是 $O(1)$，且双链表头尾的插入操作时间复杂度也是 $O(1)$。
- 我们可以在 $O(1)$ 的时间复杂度内删除指定的键值对。因为哈希表本身的删除操作时间复杂度是 $O(1)$，**删除给定双链表节点的操作时间复杂度也是 $O(1)$**。
- 由于链表节点的顺序是插入顺序，那么只要从头结点开始遍历这个链表，就能按照插入顺序访问所有键。

也就是说，我们在不改变标准哈希表的基本操作复杂度的前提下，实现了按照插入顺序访问所有键的需求。

> 链表的删除操作时间复杂度是 O(1)？
> 
> 肯定有读者记得，前文链表原理说过，链表的删除操作时间复杂度是 $O(N)$ 啊，怎么现在又说是 $O(1)$ 了？
> 
> 实际上我说的已经很严谨了，我这里说的是 **删除给定双链表节点的操作也是 $O(1)$**。
> 
> 前文我们动手实现链表的时候，我们是删除指定索引的链表节点，时间复杂度确实是 $O(N)$，因为要先遍历到这个索引，然后才能开始删除嘛。
> 
> 但是这里并没有遍历的过程，我们是直接通过哈希表键值映射拿到的这个链表节点，时间复杂度是 $O(1)$。
> 
> 且双链表节点只需进行简单的指针操作即可把自身从链表中删除，时间复杂度是 $O(1)$：
> 
> ```java
> // 删除给定双链表节点
> Node target;
> // 在双链表中删除 target 节点
> target.prev.next = target.next;
> target.next.prev = target.prev;
> target.prev = null;
> target.next = null;
> ```
> 
> 所以哈希链表删除操作的复杂度依然是 $O(1)$。
> 
> 这里需要注意，双链表节点同时拥有前后驱指针，才可以做到 $O(1)$ 时间复杂度的删除操作。单链表节点只有后驱指针，但没有前驱指针，做不到 $O(1)$ 时间复杂度的删除操作。**所以哈希链表的实现中，只能使用双链表**。

### 代码实现

明白了哈希链表的原理，直接看代码实现吧，比较简单：

```cpp
#include <iostream>
#include <unordered_map>
#include <vector>

using namespace std;


template <typename K, typename V>
struct Node {
    K key;
    V val;
    Node* next;
    Node* prev;

    Node(K key, V val) : key(key), val(val), next(nullptr), prev(nullptr) {}
};


template <typename K, typename V>
class MyLinkedHashMap {
public:
    MyLinkedHashMap() {
        head = new Node<K, V>(K(), V());
        tail = new Node<K, V>(K(), V());
        head->next = tail;
        tail->prev = head;
    }

    V get(K key) {
        if (map.find(key) == map.end()) {
            return V();
        }
        return map[key]->val;
    }

    void put(K key, V val) {
        // 若为新插入的节点，则同时插入链表和 map
        if (map.find(key) == map.end()) {
            // 插入新的 Node
            Node<K, V>* node = new Node<K, V>(key, val);
            addLastNode(node);
            map[key] = node;
            return;
        }
        // 若存在，则替换之前的 val
        map[key]->val = val;
    }

    void remove(K key) {
        // 若 key 本不存在，直接返回
        if (map.find(key) == map.end()) {
            return;
        }
        // 若 key 存在，则需要同时在哈希表和链表中删除
        Node<K, V>* node = map[key];
        map.erase(key);
        removeNode(node);
    }

    bool containsKey(K key) {
        return map.find(key) != map.end();
    }

    vector<K> keys() {
        vector<K> keyList;
        for (Node<K, V>* p = head->next; p != tail; p = p->next) {
            keyList.push_back(p->key);
        }
        return keyList;
    }

private:

    Node<K, V>* head;
    Node<K, V>* tail;
    unordered_map<K, Node<K, V>*> map;

    void addLastNode(Node<K, V>* x) {
        Node<K, V>* temp = tail->prev;
        // temp <-> tail
        x->next = tail;
        x->prev = temp;

        temp->next = x;
        tail->prev = x;
    }

    void removeNode(Node<K, V>* x) {
        Node<K, V>* prev = x->prev;
        Node<K, V>* next = x->next;
        // prev <-> x <-> next

        prev->next = next;
        next->prev = prev;

        x->next = x->prev = nullptr;
    }
};


int main() {
    MyLinkedHashMap<string, int> map;
    map.put("a", 1);
    map.put("b", 2);
    map.put("c", 3);
    map.put("d", 4);
    map.put("e", 5);

    // output: a b c d e
    for (const auto& key : map.keys()) {
        cout << key << " ";
    }
    cout << endl;

    map.remove("c");

    // output: a b d e
    for (const auto& key : map.keys()) {
        cout << key << " ";
    }
    cout << endl;

    return 0;
}
```

### `LinkedHashSet` 的实现

`LinkedHashSet` 就是一个可以保持插入顺序的哈希集合。

前文 [[4.4哈希集合的原理及代码实现]] 说过，哈希集合的代码实现其实就是包装了一下哈希表。

所以这里 `LinkedHashSet` 的实现也是直接包装一下 `MyLinkedHashMap` 即可，非常简单，我就不写代码了。

## 用数组加强哈希表

上一面我们利用双链表特性对哈希表进行了加强，实现了 `LinkedHashMap` 这种数据结构，让哈希表的键保持插入顺序。

链表能加强哈希表，数组作为链表的好兄弟，其实也能加强哈希表。

### 添加 `randomKey()` API

现在我给你出个题，让你基于标准哈希表的 API 之上，再添加一个新的 `randomKey()` API，可以在 $O(1)$ 的时间复杂度返回一个随机键：

```java
interface Map<K, V> {
    // 获取 key 对应的 value，时间复杂度 O(1)
    V get(K key);

    // 添加/修改 key-value 对，时间复杂度 O(1)
    void put(K key, V value);

    // 删除 key-value 对，时间复杂度 O(1)
    void remove(K key);

    // 是否包含 key，时间复杂度 O(1)
    boolean containsKey(K key);

    // 返回所有 key，时间复杂度 O(N)
    List<K> keys();

    // 新增 API：随机返回一个 key，要求时间复杂度 O(1)
    K randomKey();
}
```

> 均匀随机（uniform random）
> 
> 注意，我们一般说的随机，都是指均匀随机，即每个元素被选中的概率相等。比如你有 `n` 个元素，你的随机算法要保证每个元素被选中的概率都是 `1/n`，才叫均匀随机。

怎么样，你会不会做？不要小看这个简单的需求，实现方法其实是比较巧妙的。

通过前面的学习，你应该知道哈希表的本质就是一个 `table` 数组，现在让你随机返回一个哈希表的键，很容易就会联想到在数组中随机获取一个元素。

在标准数组，随机获取一个元素很简单，只要用随机数生成器生成一个 `[0, size)` 的随机索引，就相当于找了一个随机元素：

```cpp
int randomeElement(vector<int>& arr) {
    // 生成 [0, arr.size()) 的随机索引
    return arr[rand() % arr.size()];
}
```

这个算法是正确的，它的复杂度是 $O(1)$，且每个元素被选中的概率都是 `1/n`，`n` 为 `arr` 数组的总元素个数。

但你注意，上面这个函数有个前提，就是数组中的元素是紧凑存储没有空洞的，比如 `arr = [1, 2, 3, 4]`，这样才能保证任意一个随机索引都对应一个有效的元素。

如果数组中有空洞就有问题了，比如 `arr = [1, 2, null, 4]`，其中 `arr[2] = null` 代表没有存储元素的空洞，那么如果你生成的随机数恰好是 2，请问你该怎么办？

也许你想说，可以向左或者向右线性查找，找到一个非空的元素返回，类似这样：

```plain
// 返回一个非空的随机元素（伪码）
int randomeElement(int[] arr) {
    Random r = new Random();
    // 生成 [0, arr.length) 的随机索引
    int i = r.nextInt(arr.length);
    while (arr[i] == null) {
        // 随机生成的索引 i 恰巧是空洞
        // 借助环形数组技巧向右进行探查
        // 直到找到一个非空元素
        i = (i + 1) % arr.length;
    }
    return arr[i];
}
```

你这样是不行的，这个算法有两个问题：

1、有个循环，最坏时间复杂度上升到了 $O(N)$，不符合 $O(1)$ 的要求。

2、这个算法不是均匀随机的，因为你的查找方向是固定的，空洞右侧的元素被选中的概率会更大。比如 `arr = [1, 2, null, 4]`，元素 `1, 2, 4` 被选中的概率分别是 `1/4, 1/4, 2/4`。

那也许还有个办法，一次运气不好，就多来随机几次，直到找到一个非空元素：

```plain
// 返回一个非空的随机元素（伪码）
int randomeElement(int[] arr) {
    Random r = new Random();
    // 生成 [0, arr.length) 的随机索引
    int i = r.nextInt(arr.length);
    while (arr[i] == null) {
        // 随机生成的索引 i 恰巧是空洞
        // 重新生成一个随机索引
        i = r.nextInt(arr.length);
    }
    return arr[i];
}
```

现在这个算法是均匀随机的，但问题也非常明显，它的时间复杂度竟然依赖随机数！肯定不是 $O(1)$ 的，不符合要求。

怎么样，从一个带有空洞的数组中随机返回一个元素是不是都把你难住了？

别忘了，我们现在的目标是从哈希表中随机返回一个键，**哈希表底层的 `table` 数组不仅包含空洞，情况还会更复杂一些**：

![image.png](https://typora-yzj.oss-cn-hangzhou.aliyuncs.com/img/20250104232206.png)

如果你的哈希表用开放寻址法解决哈希冲突，那还好，就是带空洞数组的场景。

如果你的哈希表用拉链法，那可麻烦了。数组里面的每个元素是一个链表，你光随机一个索引是不够的，还要随机链表中的一个节点。

而且注意概率，这个拉链法，就算你均匀随机到一个数组索引，又均匀随机该索引存储的链表节点，得到的这个键是均匀随机的么？

其实不是，上图中 `k1, k2, k3` 被随机到的概率是 `1/2 * 1/3 = 1/6`，而 `k4, k5` 被随机到的概率是 `1/2 * 1/2 = 1/4`，这不是均匀随机。

> 关于概率算法
> 
> 概率算法也是非常有意思的一类问题，无论算法题还是实际业务中都会用到一些经典的随机算法，我会在后文==谈谈游戏中的随机算法==和==带权重的随机选择==中详细讲解，这里暂时不需要掌握。

唯一的办法就是通过 `keys` 方法遍历整个 `table` 数组，把所有的键都存储到一个数组中，然后再随机返回一个键。但这样复杂度就是 $O(N)$ 了，还是不符合要求。

是不是感觉已经走投无路了？所以说，还是要积累一些经典数据结构设计经验，如果面试笔试的时候遇到类似的问题，你现场想恐怕是很难的。下面我就来介绍一下如何用数组加强哈希表，轻松实现 `randomKey()` API。

### 实现思路

其实我前面给你分析拉链法，就是故意误导你的。和前文链表加强哈希表一样，只要你陷入到细节里面，那肯定觉得很复杂。

所以说，不要陷入细节。那什么拉链法线性探查法，只是给你介绍下哈希表的运行原理，了解一下为啥它的复杂度是那样。

现在，以及未来做题的时候，你只要记住哈希表是一个能进行键值操作的数据结构，就行了，把它当成一个黑盒，不要去管它的底层实现。

紧凑的数组可以随机返回一个元素，现在我们想随机返回哈希表的一个键，那么最简单的方法就是这样：

```plain
// 伪码思路
class MyArrayHashMap {
    // arr 数组存储哈希表中所有的 key
    vector<int> arr;
    unordered_map<int, int> map;

    // 添加/修改 key-value 对，时间复杂度 O(1)
    void put(int key, int value) {
        if (!map.count(key)) {
            // 新增的 key 加入到 arr 数组中
            arr.push_back(key);
        }
        map[key] = value;
    }

    // 获取 key 对应的 value，时间复杂度 O(1)
    int get(int key) {
        return map[key];
    }

    // 新增 API：随机返回一个 key，要求时间复杂度 O(1)
    int randomKey() {
        // 生成 [0, arr.size()) 的随机索引
        return arr[rand() % arr.size()];
    }

    // 删除 key-value 对，时间复杂度 O(1)
    void remove(int key) {
        ...
    }
};
```

这个思路非常简单，就是用一个数组 `arr` 维护哈希表中所有的键，然后通过随机索引返回一个键。这样就能保证均匀随机，且时间复杂度是 $O(1)$。

但你注意，我没有实现哈希表的 `remove` 方法。因为这个方法不仅要删除哈希表 `map` 中的 `key`，还要删除 `arr` 数组中的元素 `key`，而删除数组中的元素时间复杂度是 $O(N)$，因为我们需要搬移数据以保持元素的连续性。

**那么有没有办法让 `arr` 数组不用搬移数据，还能保持元素的连续性呢？**。

> $O(1)$ 时间删除数组中的任意元素
> 
> 其实可以做到。你可以把待删除的元素，先交换到数组尾部，然后再删除，数组尾部删除元素的时间复杂度是 $O(1)$。

比如 `arr = [1, 2, 3, 4, 5]`，如果要删除 `2`，我先把 `2` 交换到数组尾部，变成 `arr = [1, 5, 3, 4, 2]`，然后只需花 O(1) 的时间即可删除尾部元素 `2`，且数组的连续性不会被破坏。

是不是思路一下就打开了？

但现在还有个问题，就是你如何快速知道一个元素在数组中对应的索引呢？正常来说，需要遍历数组，找到元素对应的索引，这样时间复杂度是 $O(N)$。

但是现在不是有哈希表么，键值映射是干啥的？不就是帮你优化这种需要傻乎乎遍历的场景的么？

也就是说，你可以在哈希表中建立数组元素和数组索引的映射关系，这样你就能在 $O(1)$ 的时间复杂度内找到数组元素对应的索引了。

好了，讲到这里，整个思路已经比较清晰，下面直接看代码实现吧。

### 代码实现

```cpp
#include <iostream>
#include <random>
#include <vector>
#include <unordered_map>

using namespace std;

template<typename K, typename V>
class MyArrayHashMap {
    struct Node {
        K key;
        V val;

        Node(K key, V val) : key(key), val(val) {
        }
    };

    // 存储 key 和 key 在 arr 中的索引
    unordered_map<K, int> map;

    // 真正存储 key-value 的数组
    vector<Node> arr;

    // 随机数生成器
    default_random_engine e;

public:

    MyArrayHashMap() {
        e.seed(random_device()());
    }

    V get(K key) {
        if (!map.count(key)) {
            return NULL;
        }
        int index = map[key];
        return arr[index].val;
    }

    void put(K key, V val) {
        if (containsKey(key)) {
            // 修改
            int i = map[key];
            arr[i].val = val;
            return;
        }

        // 新增
        arr.push_back(Node(key, val));
        map[key] = arr.size() - 1;
    }

    void remove(K key) {
        if (!map.count(key)) {
            return;
        }
        int index = map[key];
        Node node = arr[index];

        // 1. 最后一个元素 e 和第 index 个元素 node 换位置
        Node e = arr.back();
        swap(arr[index], e);

        // 2. 修改 map 中 e.key 对应的索引
        map[e.key] = index;

        // 3. 在数组中删除最后一个元素
        arr.pop_back();

        // 4. 在 map 中删除 node.key
        map.erase(node.key);
    }

    // 随机弹出一个键
    K randomKey() {
        int n = arr.size();
        uniform_int_distribution<int> u(0, n - 1);
        int randomIndex = u(e);
        return arr[randomIndex].key;
    }

    bool containsKey(K key) {
        return map.count(key);
    }

    int size() {
        return map.size();
    }
};

int main() {
    MyArrayHashMap<int, int> map;
    map.put(1, 1);
    map.put(2, 2);
    map.put(3, 3);
    map.put(4, 4);
    map.put(5, 5);

    cout << map.get(1) << endl; // 1
    cout << map.randomKey() << endl;

    map.remove(4);
    cout << map.randomKey() << endl;
    cout << map.randomKey() << endl;

    return 0;
}
```

到这里，`ArrayHashMap` 结构就实现完了。如果你想实现 `ArrayHashSet`，只需要简单封装 `ArrayHashMap` 即可，我这里就不写代码了。